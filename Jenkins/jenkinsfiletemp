pipeline {
    agent any
    
    // Pipeline is triggered by Bitbucket webhooks
    
    parameters {
        string(
            name: 'BRANCH_NAME',
            defaultValue: '',
            description: 'Branch name from Bitbucket webhook (auto-populated)'
        )
        booleanParam(
            name: 'FORCE_API_DEPLOY',
            defaultValue: false,
            description: 'Force API deployment regardless of changes'
        )
        booleanParam(
            name: 'FORCE_DAG_DEPLOY',
            defaultValue: false,
            description: 'Force DAG deployment regardless of changes'
        )
        booleanParam(
            name: 'RUN_BRANCH_CLEANUP',
            defaultValue: false,
            description: 'Run branch cleanup after deployment'
        )
        booleanParam(
            name: 'SINGLE_TAG_ONLY',
            defaultValue: true,  // Changed to true - only push versioned tag
            description: 'Push only versioned tag (skip latest tag)'
        )
    }
    
    environment {
        // GCP Configuration
        GCP_PROJECT_ID = 'prj-srv-data-lake-uate7'
        GCP_REGION = 'asia-south1'
        
        // Container Registry Configuration
        REGISTRY_REPOSITORY = 'nginx'  // Repository name in Artifact Registry
        IMAGE_NAME = 'hdfcergo-duckcreek'
        
        // Dynamic Image Tag: BUILD_NUMBER-GIT_COMMIT_SHORT
        IMAGE_TAG = "${BUILD_NUMBER}-${GIT_COMMIT.take(7)}"
        
        // Full registry path
        ARTIFACT_REGISTRY = "${GCP_REGION}-docker.pkg.dev/${GCP_PROJECT_ID}/${REGISTRY_REPOSITORY}"
        
        // Cloud Run Configuration (update these service names as needed)
        CLOUD_RUN_SERVICE_UAT = 'hdfcergo-duckcreek-uat'
        CLOUD_RUN_SERVICE_PROD = 'hdfcergo-duckcreek-prod'
        
        // Cloud Storage for DAGs (update project ID if different for GCS)
        GCS_PROJECT_ID = 'prj-srv-data-lake-uate7'  // Can be different from main project
        GCS_BUCKET_UAT = "gs://${GCS_PROJECT_ID}-airflow-dags-uat"
        GCS_BUCKET_PROD = "gs://${GCS_PROJECT_ID}-airflow-dags-prod"
        
        // Service Account
        GCP_SA_KEY = credentials('gcp-service-account-key')
        
        // Paths
        API_PATH = 'api/'
        DAG_PATH = 'dags/'
        
        // Change Detection Flags
        API_CHANGED = 'false'
        DAG_CHANGED = 'false'
        
        // Branch Cleanup
        PROTECTED_BRANCHES = 'main,master,develop,dev,uat,prod,production,staging'
        BRANCH_CLEANUP_DAYS = '30'
    }
    
    stages {
        stage('Initialize') {
            steps {
                script {
                    echo "=" * 80
                    echo "CI/CD Pipeline Triggered by Bitbucket Webhook"
                    echo "=" * 80
                    echo "Checkout and determine environment..."
                    checkout scm
                    
                    // Determine environment from branch name
                    def branch = env.GIT_BRANCH ?: params.BRANCH_NAME ?: 'unknown'
                    echo "Detected branch: ${branch}"
                    
                    if (branch.contains('prod') || branch.contains('main')) {
                        env.TARGET_ENV = 'PROD'
                        env.GCS_BUCKET = env.GCS_BUCKET_PROD
                        env.CLOUD_RUN_SERVICE = env.CLOUD_RUN_SERVICE_PROD
                    } else if (branch.contains('uat') || branch.contains('dev')) {
                        env.TARGET_ENV = 'UAT'
                        env.GCS_BUCKET = env.GCS_BUCKET_UAT
                        env.CLOUD_RUN_SERVICE = env.CLOUD_RUN_SERVICE_UAT
                    } else {
                        error("‚ö†Ô∏è Deployment not allowed for branch: ${branch}. Only prod/main/uat/dev branches are supported.")
                    }
                    
                    echo "üéØ Target Environment: ${env.TARGET_ENV}"
                    echo "üì¶ GCS Bucket: ${env.GCS_BUCKET}"
                    echo "‚òÅÔ∏è  Cloud Run Service: ${env.CLOUD_RUN_SERVICE}"
                }
            }
        }
        
        stage('Detect Changes') {
            steps {
                script {
                    echo "Analyzing changes to determine deployment scope..."
                    
                    // Check for API changes
                    def apiChanges = sh(
                        script: """
                            if [ \$(git diff HEAD~1 HEAD --name-only | grep '^${API_PATH}' | wc -l) -gt 0 ]; then
                                echo 'true'
                            else
                                echo 'false'
                            fi
                        """,
                        returnStdout: true
                    ).trim()
                    
                    // Check for DAG changes
                    def dagChanges = sh(
                        script: """
                            if [ \$(git diff HEAD~1 HEAD --name-only | grep '^${DAG_PATH}' | wc -l) -gt 0 ]; then
                                echo 'true'
                            else
                                echo 'false'
                            fi
                        """,
                        returnStdout: true
                    ).trim()
                    
                    env.API_CHANGED = params.FORCE_API_DEPLOY ? 'true' : apiChanges
                    env.DAG_CHANGED = params.FORCE_DAG_DEPLOY ? 'true' : dagChanges
                    
                    echo "üìä Change Detection Results:"
                    echo "   API Changes: ${env.API_CHANGED}"
                    echo "   DAG Changes: ${env.DAG_CHANGED}"
                    
                    if (env.API_CHANGED == 'false' && env.DAG_CHANGED == 'false') {
                        echo "‚ö†Ô∏è No changes detected in API or DAG paths."
                        echo "   Pipeline will skip deployment and proceed to cleanup if enabled."
                        currentBuild.description = "No deployment needed - no changes in api/ or dags/"
                    }
                }
            }
        }
        
        stage('GCP Authentication') {
            when {
                expression { 
                    env.API_CHANGED == 'true' || env.DAG_CHANGED == 'true' 
                }
            }
            steps {
                script {
                    echo "Authenticating with GCP..."
                    sh """
                        gcloud auth activate-service-account --key-file=\${GCP_SA_KEY}
                        gcloud config set project \${GCP_PROJECT_ID}
                    """
                }
            }
        }
        
        stage('API Deployment') {
            when {
                expression { env.API_CHANGED == 'true' }
            }
            stages {
                stage('Docker Build') {
                    steps {
                        script {
                            echo "Building Docker image for API..."
                            sh """
                                cd ${API_PATH}
                                docker build -t ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG} .
                            """
                            echo "‚úÖ Built image: ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG}"
                        }
                    }
                }
                
                stage('Push to Artifact Registry') {
                    steps {
                        script {
                            echo "Pushing Docker image to Artifact Registry..."
                            sh """
                                gcloud auth configure-docker ${GCP_REGION}-docker.pkg.dev
                                docker push ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG}
                            """
                            echo "‚úÖ Pushed: ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG}"
                        }
                    }
                }
                
                stage('Deploy to Cloud Run') {
                    steps {
                        script {
                            echo "Deploying to Cloud Run (${env.TARGET_ENV})..."
                            sh """
                                gcloud run deploy ${CLOUD_RUN_SERVICE} \
                                    --image=${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG} \
                                    --region=${GCP_REGION} \
                                    --platform=managed \
                                    --allow-unauthenticated \
                                    --max-instances=10 \
                                    --memory=512Mi \
                                    --cpu=1 \
                                    --timeout=300s \
                                    --port=8080
                            """
                            
                            // Get Cloud Run URL
                            env.CLOUD_RUN_URL = sh(
                                script: "gcloud run services describe ${CLOUD_RUN_SERVICE} --region=${GCP_REGION} --format='value(status.url)'",
                                returnStdout: true
                            ).trim()
                            
                            echo "‚úÖ API deployed successfully to: ${env.CLOUD_RUN_URL}"
                        }
                    }
                }
                
                stage('Health Check') {
                    steps {
                        script {
                            echo "Performing health check on deployed API..."
                            retry(3) {
                                sleep(time: 5, unit: 'SECONDS')
                                sh """
                                    curl -f ${env.CLOUD_RUN_URL}/health || curl -f ${env.CLOUD_RUN_URL}/ || exit 1
                                """
                            }
                            echo "‚úÖ Health check passed"
                        }
                    }
                }
            }
        }
        
        stage('DAG Deployment') {
            when {
                expression { env.DAG_CHANGED == 'true' }
            }
            stages {
                stage('Validate DAG Files') {
                    steps {
                        script {
                            echo "Validating DAG files..."
                            sh """
                                cd ${DAG_PATH}
                                
                                # Check for Python syntax errors
                                find . -name "*.py" -exec python3 -m py_compile {} \\;
                                
                                echo "‚úÖ DAG validation completed"
                            """
                        }
                    }
                }
                
                stage('Sync to Cloud Storage') {
                    steps {
                        script {
                            echo "Syncing DAG files to Cloud Storage (${env.TARGET_ENV})..."
                            sh """
                                gsutil -m rsync -r -d ${DAG_PATH} ${GCS_BUCKET}/dags/
                                
                                # Set appropriate permissions
                                gsutil -m acl ch -r -u AllUsers:R ${GCS_BUCKET}/dags/ || true
                            """
                            echo "‚úÖ DAG files synced to: ${env.GCS_BUCKET}/dags/"
                        }
                    }
                }
                
                stage('Verify Cloud Composer') {
                    steps {
                        script {
                            echo "Verifying Cloud Composer can access DAGs..."
                            sh """
                                # List uploaded files
                                gsutil ls ${GCS_BUCKET}/dags/
                            """
                            echo "‚úÖ DAG deployment completed. Airflow will refresh DAGs automatically."
                        }
                    }
                }
            }
        }
        
        stage('Cleanup Docker Images') {
            when {
                expression { env.API_CHANGED == 'true' }
            }
            steps {
                script {
                    echo "Cleaning up local Docker images..."
                    sh """
                        docker rmi ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG} || true
                        docker system prune -f
                    """
                }
            }
        }
        
        stage('Branch Cleanup') {
            when {
                anyOf {
                    expression { params.RUN_BRANCH_CLEANUP == true }
                    expression { env.TARGET_ENV == 'PROD' } // Auto-cleanup after prod deploys
                }
            }
            stages {
                stage('Fetch All Branches') {
                    steps {
                        script {
                            echo "=" * 80
                            echo "Starting Branch Cleanup Process"
                            echo "=" * 80
                            sh 'git fetch --prune origin'
                        }
                    }
                }
                
                stage('Identify Stale Branches') {
                    steps {
                        script {
                            echo "Scanning for stale branches (older than ${env.BRANCH_CLEANUP_DAYS} days)..."
                            
                            // Get list of all remote branches with their last commit dates
                            def branchesScript = """
                                git for-each-ref --sort=-committerdate refs/remotes/origin/ \
                                    --format='%(refname:short)|%(committerdate:unix)|%(authorname)' | \
                                    sed 's|origin/||'
                            """
                            
                            def branchesOutput = sh(script: branchesScript, returnStdout: true).trim()
                            def branches = branchesOutput.split('\n')
                            
                            def currentTimestamp = sh(script: 'date +%s', returnStdout: true).trim().toLong()
                            def thresholdSeconds = env.BRANCH_CLEANUP_DAYS.toInteger() * 24 * 60 * 60
                            def protectedList = env.PROTECTED_BRANCHES.split(',').collect { it.trim() }
                            
                            def staleBranches = []
                            def protectedBranches = []
                            def activeBranches = []
                            
                            branches.each { branchInfo ->
                                if (branchInfo.trim()) {
                                    def parts = branchInfo.split('\\|')
                                    def branchName = parts[0]
                                    def commitTimestamp = parts[1].toLong()
                                    def author = parts.size() > 2 ? parts[2] : 'Unknown'
                                    
                                    def ageInDays = ((currentTimestamp - commitTimestamp) / (24 * 60 * 60)).toInteger()
                                    
                                    // Skip HEAD
                                    if (branchName == 'HEAD') {
                                        return
                                    }
                                    
                                    // Check if branch is protected
                                    if (protectedList.contains(branchName)) {
                                        protectedBranches << [name: branchName, age: ageInDays, author: author]
                                        return
                                    }
                                    
                                    // Check if branch is stale
                                    if ((currentTimestamp - commitTimestamp) > thresholdSeconds) {
                                        staleBranches << [name: branchName, age: ageInDays, author: author]
                                    } else {
                                        activeBranches << [name: branchName, age: ageInDays, author: author]
                                    }
                                }
                            }
                            
                            // Store results
                            env.STALE_BRANCHES_COUNT = staleBranches.size().toString()
                            env.ACTIVE_BRANCHES_COUNT = activeBranches.size().toString()
                            env.PROTECTED_BRANCHES_COUNT = protectedBranches.size().toString()
                            
                            // Generate report
                            def report = "\n" + "=" * 80 + "\n"
                            report += "Branch Cleanup Report\n"
                            report += "=" * 80 + "\n\n"
                            
                            report += "üìä Summary:\n"
                            report += "-" * 80 + "\n"
                            report += "Total Branches Scanned: ${branches.size()}\n"
                            report += "Protected Branches: ${protectedBranches.size()}\n"
                            report += "Active Branches: ${activeBranches.size()}\n"
                            report += "Stale Branches (${env.BRANCH_CLEANUP_DAYS}+ days): ${staleBranches.size()}\n\n"
                            
                            if (staleBranches.size() > 0) {
                                report += "üóëÔ∏è  Stale Branches to be deleted:\n"
                                report += "-" * 80 + "\n"
                                staleBranches.sort { -it.age }.each { branch ->
                                    report += sprintf("%-40s | %4d days | %s\n", 
                                        branch.name, branch.age, branch.author)
                                }
                                report += "\n"
                            } else {
                                report += "‚úÖ No stale branches found!\n\n"
                            }
                            
                            echo report
                            
                            // Save report to workspace
                            writeFile file: 'branch-cleanup-report.txt', text: report
                            
                            // Save stale branches list for next stage
                            if (staleBranches.size() > 0) {
                                def branchList = staleBranches.collect { it.name }.join('\n')
                                writeFile file: 'stale-branches.txt', text: branchList
                            }
                        }
                    }
                }
                
                stage('Delete Stale Branches') {
                    when {
                        expression { env.STALE_BRANCHES_COUNT.toInteger() > 0 }
                    }
                    steps {
                        script {
                            echo "Deleting ${env.STALE_BRANCHES_COUNT} stale branches from remote repository..."
                            
                            def staleBranches = readFile('stale-branches.txt').split('\n')
                            def deletedCount = 0
                            def failedCount = 0
                            def failedBranches = []
                            
                            staleBranches.each { branchName ->
                                if (branchName.trim()) {
                                    try {
                                        echo "Deleting branch: ${branchName}"
                                        sh """
                                            git push origin --delete ${branchName}
                                        """
                                        deletedCount++
                                        echo "‚úÖ Deleted: ${branchName}"
                                    } catch (Exception e) {
                                        failedCount++
                                        failedBranches << branchName
                                        echo "‚ùå Failed to delete: ${branchName} - ${e.message}"
                                    }
                                }
                            }
                            
                            env.DELETED_COUNT = deletedCount.toString()
                            env.FAILED_COUNT = failedCount.toString()
                            
                            def deletionSummary = "\nDeletion Summary:\n"
                            deletionSummary += "-" * 80 + "\n"
                            deletionSummary += "Successfully Deleted: ${deletedCount} branches\n"
                            
                            if (failedCount > 0) {
                                deletionSummary += "Failed to Delete: ${failedCount} branches\n"
                                deletionSummary += "\nFailed Branches:\n"
                                failedBranches.each { branch ->
                                    deletionSummary += "  - ${branch}\n"
                                }
                            }
                            
                            echo deletionSummary
                            
                            // Append to report
                            sh """
                                echo "\n${deletionSummary}" >> branch-cleanup-report.txt
                            """
                        }
                    }
                }
                
                stage('Archive Cleanup Report') {
                    when {
                        expression { fileExists('branch-cleanup-report.txt') }
                    }
                    steps {
                        script {
                            echo "Archiving cleanup report..."
                            archiveArtifacts artifacts: 'branch-cleanup-report.txt', fingerprint: true
                        }
                    }
                }
            }
        }
    }
    
    post {
        success {
            script {
                def deploymentSummary = "üéâ Pipeline Completed Successfully!\n\n"
                deploymentSummary += "Triggered by: Bitbucket Webhook\n"
                deploymentSummary += "Branch: ${env.GIT_BRANCH}\n"
                deploymentSummary += "Environment: ${env.TARGET_ENV}\n\n"
                
                if (env.API_CHANGED == 'true') {
                    deploymentSummary += "‚úÖ API Deployment:\n"
                    deploymentSummary += "   - Image: ${ARTIFACT_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG}\n"
                    deploymentSummary += "   - Service: ${env.CLOUD_RUN_SERVICE}\n"
                    deploymentSummary += "   - URL: ${env.CLOUD_RUN_URL}\n\n"
                }
                
                if (env.DAG_CHANGED == 'true') {
                    deploymentSummary += "‚úÖ DAG Deployment:\n"
                    deploymentSummary += "   - Bucket: ${env.GCS_BUCKET}/dags/\n"
                    deploymentSummary += "   - Cloud Composer will refresh automatically\n\n"
                }
                
                if (env.STALE_BRANCHES_COUNT && env.STALE_BRANCHES_COUNT.toInteger() > 0) {
                    deploymentSummary += "üóëÔ∏è  Branch Cleanup:\n"
                    deploymentSummary += "   - Stale branches found: ${env.STALE_BRANCHES_COUNT}\n"
                    deploymentSummary += "   - Successfully deleted: ${env.DELETED_COUNT ?: '0'}\n"
                    if (env.FAILED_COUNT && env.FAILED_COUNT.toInteger() > 0) {
                        deploymentSummary += "   - Failed to delete: ${env.FAILED_COUNT}\n"
                    }
                    deploymentSummary += "\n"
                }
                
                deploymentSummary += "Build: #${BUILD_NUMBER}\n"
                deploymentSummary += "Commit: ${GIT_COMMIT.take(7)}\n"
                
                echo deploymentSummary
                
                // Set build description for easy identification
                def description = "${env.TARGET_ENV}: "
                if (env.API_CHANGED == 'true') description += "API‚úÖ "
                if (env.DAG_CHANGED == 'true') description += "DAG‚úÖ "
                if (env.STALE_BRANCHES_COUNT && env.STALE_BRANCHES_COUNT.toInteger() > 0) {
                    description += "Cleanup:${env.DELETED_COUNT}üóëÔ∏è"
                }
                currentBuild.description = description
            }
        }
        
        failure {
            script {
                def failureMessage = "‚ùå Pipeline Failed!\n\n"
                failureMessage += "Triggered by: Bitbucket Webhook\n"
                failureMessage += "Branch: ${env.GIT_BRANCH}\n"
                failureMessage += "Environment: ${env.TARGET_ENV}\n"
                failureMessage += "Build: #${BUILD_NUMBER}\n"
                failureMessage += "Commit: ${GIT_COMMIT.take(7)}\n\n"
                failureMessage += "Check Jenkins console output for details:\n"
                failureMessage += "${BUILD_URL}console"
                
                echo failureMessage
            }
        }
        
        always {
            cleanWs()
        }
    }
}